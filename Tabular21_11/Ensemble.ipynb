{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d3c5e1-094a-4890-8216-926d75110ef7",
   "metadata": {},
   "source": [
    "# Reference\n",
    "###  https://www.kaggle.com/yuyougnchan/tps-nov-lightgbm-baseline/notebook\n",
    "### https://www.kaggle.com/sergiosaharovskiy/tps-nov-2021-a-complete-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5868c1-8d1b-41a9-a157-679e33b150ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e6894a-df07-47be-83a6-6090e482f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, RandomForestRegressor\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay, ConfusionMatrixDisplay, confusion_matrix, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf37a518-513b-4a26-b8ac-09fdf85bca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH =\"./dataset/\"\n",
    "train = pd.read_csv(DATASET_PATH + \"train.csv\")\n",
    "test = pd.read_csv(DATASET_PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1780ad81-46d9-4c84-a8f8-88b0a9382ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()[train.isnull().sum() != 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb4d200-4cf9-4b40-8b34-2968147dd0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.drop(['id'],axis=1)\n",
    "test_df = test.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "952bd53d-91ec-4490-9040-3b0e03c3dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f4ac4b-af10-4a88-ae43-10e07c61332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('target', axis=1)\n",
    "Y = train_df['target']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2,\n",
    "                                                     shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "183f6011-8f58-41e9-89de-1cd5ef23fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['f'+str(i) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f60c4df0-6dc6-471d-9f10-21db62b2b77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106643</td>\n",
       "      <td>3.594370</td>\n",
       "      <td>132.8040</td>\n",
       "      <td>3.184280</td>\n",
       "      <td>0.081971</td>\n",
       "      <td>1.18859</td>\n",
       "      <td>3.732380</td>\n",
       "      <td>2.266270</td>\n",
       "      <td>2.099590</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>1.098620</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>-0.011715</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>4.211250</td>\n",
       "      <td>1.978770</td>\n",
       "      <td>0.085974</td>\n",
       "      <td>0.240496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125021</td>\n",
       "      <td>1.673360</td>\n",
       "      <td>76.5336</td>\n",
       "      <td>3.378250</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>5.09366</td>\n",
       "      <td>1.275620</td>\n",
       "      <td>-0.471318</td>\n",
       "      <td>4.545940</td>\n",
       "      <td>0.037706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135838</td>\n",
       "      <td>3.460170</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.124863</td>\n",
       "      <td>0.154064</td>\n",
       "      <td>0.606848</td>\n",
       "      <td>-0.267928</td>\n",
       "      <td>2.577860</td>\n",
       "      <td>-0.020877</td>\n",
       "      <td>0.024719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036330</td>\n",
       "      <td>1.497470</td>\n",
       "      <td>233.5460</td>\n",
       "      <td>2.194350</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>3.12694</td>\n",
       "      <td>5.056870</td>\n",
       "      <td>3.849460</td>\n",
       "      <td>1.801870</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117310</td>\n",
       "      <td>4.883000</td>\n",
       "      <td>0.085222</td>\n",
       "      <td>0.032396</td>\n",
       "      <td>0.116092</td>\n",
       "      <td>-0.001688</td>\n",
       "      <td>-0.520069</td>\n",
       "      <td>2.141120</td>\n",
       "      <td>0.124464</td>\n",
       "      <td>0.148209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014077</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>779.9670</td>\n",
       "      <td>1.890640</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>1.53112</td>\n",
       "      <td>2.698000</td>\n",
       "      <td>4.517330</td>\n",
       "      <td>4.503320</td>\n",
       "      <td>0.123494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015347</td>\n",
       "      <td>3.474390</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>-0.008100</td>\n",
       "      <td>0.062013</td>\n",
       "      <td>0.041193</td>\n",
       "      <td>0.511657</td>\n",
       "      <td>1.968600</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>0.044873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003259</td>\n",
       "      <td>3.715420</td>\n",
       "      <td>156.1280</td>\n",
       "      <td>2.147720</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>2.09859</td>\n",
       "      <td>4.154920</td>\n",
       "      <td>-0.038236</td>\n",
       "      <td>3.371450</td>\n",
       "      <td>0.034166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013781</td>\n",
       "      <td>1.910590</td>\n",
       "      <td>-0.042943</td>\n",
       "      <td>0.105616</td>\n",
       "      <td>0.125072</td>\n",
       "      <td>0.037509</td>\n",
       "      <td>1.043790</td>\n",
       "      <td>1.074810</td>\n",
       "      <td>-0.012819</td>\n",
       "      <td>0.072798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>0.043008</td>\n",
       "      <td>1.640550</td>\n",
       "      <td>1375.8900</td>\n",
       "      <td>1.087030</td>\n",
       "      <td>0.839580</td>\n",
       "      <td>1.69362</td>\n",
       "      <td>3.843520</td>\n",
       "      <td>1.108250</td>\n",
       "      <td>1.505390</td>\n",
       "      <td>-0.022177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046537</td>\n",
       "      <td>1.552280</td>\n",
       "      <td>0.080317</td>\n",
       "      <td>0.017643</td>\n",
       "      <td>0.225133</td>\n",
       "      <td>0.073179</td>\n",
       "      <td>4.436510</td>\n",
       "      <td>1.739330</td>\n",
       "      <td>0.049038</td>\n",
       "      <td>0.065804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>0.137048</td>\n",
       "      <td>4.826860</td>\n",
       "      <td>-99.6478</td>\n",
       "      <td>0.985289</td>\n",
       "      <td>0.037712</td>\n",
       "      <td>3.30370</td>\n",
       "      <td>2.471790</td>\n",
       "      <td>5.942130</td>\n",
       "      <td>0.875148</td>\n",
       "      <td>-0.009738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109293</td>\n",
       "      <td>1.345210</td>\n",
       "      <td>0.092457</td>\n",
       "      <td>0.081926</td>\n",
       "      <td>0.234041</td>\n",
       "      <td>0.041383</td>\n",
       "      <td>3.873990</td>\n",
       "      <td>1.870100</td>\n",
       "      <td>0.162313</td>\n",
       "      <td>0.085662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>1.316220</td>\n",
       "      <td>0.502062</td>\n",
       "      <td>66.2360</td>\n",
       "      <td>2.233020</td>\n",
       "      <td>0.060038</td>\n",
       "      <td>3.77371</td>\n",
       "      <td>2.655340</td>\n",
       "      <td>3.155890</td>\n",
       "      <td>1.055020</td>\n",
       "      <td>0.025137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117131</td>\n",
       "      <td>2.181150</td>\n",
       "      <td>0.032708</td>\n",
       "      <td>0.109668</td>\n",
       "      <td>0.027466</td>\n",
       "      <td>0.061931</td>\n",
       "      <td>-0.383329</td>\n",
       "      <td>0.922113</td>\n",
       "      <td>0.084864</td>\n",
       "      <td>0.052635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>0.511918</td>\n",
       "      <td>3.827470</td>\n",
       "      <td>777.8720</td>\n",
       "      <td>0.285914</td>\n",
       "      <td>0.520157</td>\n",
       "      <td>2.76285</td>\n",
       "      <td>2.522200</td>\n",
       "      <td>1.561360</td>\n",
       "      <td>1.971140</td>\n",
       "      <td>0.461982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072443</td>\n",
       "      <td>0.366702</td>\n",
       "      <td>0.070943</td>\n",
       "      <td>0.071452</td>\n",
       "      <td>-0.038071</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>-0.122888</td>\n",
       "      <td>3.107790</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>0.004179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>0.179347</td>\n",
       "      <td>3.457390</td>\n",
       "      <td>160.5980</td>\n",
       "      <td>3.297320</td>\n",
       "      <td>0.102784</td>\n",
       "      <td>1.89434</td>\n",
       "      <td>0.057866</td>\n",
       "      <td>2.073280</td>\n",
       "      <td>1.191480</td>\n",
       "      <td>0.025498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088059</td>\n",
       "      <td>2.282780</td>\n",
       "      <td>0.160674</td>\n",
       "      <td>0.029301</td>\n",
       "      <td>1.059810</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>3.732990</td>\n",
       "      <td>1.965300</td>\n",
       "      <td>0.049075</td>\n",
       "      <td>0.044436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f0        f1         f2        f3        f4       f5        f6  \\\n",
       "0       0.106643  3.594370   132.8040  3.184280  0.081971  1.18859  3.732380   \n",
       "1       0.125021  1.673360    76.5336  3.378250  0.099400  5.09366  1.275620   \n",
       "2       0.036330  1.497470   233.5460  2.194350  0.026914  3.12694  5.056870   \n",
       "3      -0.014077  0.246000   779.9670  1.890640  0.006948  1.53112  2.698000   \n",
       "4      -0.003259  3.715420   156.1280  2.147720  0.018284  2.09859  4.154920   \n",
       "...          ...       ...        ...       ...       ...      ...       ...   \n",
       "599995  0.043008  1.640550  1375.8900  1.087030  0.839580  1.69362  3.843520   \n",
       "599996  0.137048  4.826860   -99.6478  0.985289  0.037712  3.30370  2.471790   \n",
       "599997  1.316220  0.502062    66.2360  2.233020  0.060038  3.77371  2.655340   \n",
       "599998  0.511918  3.827470   777.8720  0.285914  0.520157  2.76285  2.522200   \n",
       "599999  0.179347  3.457390   160.5980  3.297320  0.102784  1.89434  0.057866   \n",
       "\n",
       "              f7        f8        f9  ...       f90       f91       f92  \\\n",
       "0       2.266270  2.099590  0.012330  ...  0.010739  1.098620  0.013331   \n",
       "1      -0.471318  4.545940  0.037706  ...  0.135838  3.460170  0.017054   \n",
       "2       3.849460  1.801870  0.056995  ...  0.117310  4.883000  0.085222   \n",
       "3       4.517330  4.503320  0.123494  ... -0.015347  3.474390 -0.017103   \n",
       "4      -0.038236  3.371450  0.034166  ...  0.013781  1.910590 -0.042943   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "599995  1.108250  1.505390 -0.022177  ...  0.046537  1.552280  0.080317   \n",
       "599996  5.942130  0.875148 -0.009738  ...  0.109293  1.345210  0.092457   \n",
       "599997  3.155890  1.055020  0.025137  ...  0.117131  2.181150  0.032708   \n",
       "599998  1.561360  1.971140  0.461982  ...  0.072443  0.366702  0.070943   \n",
       "599999  2.073280  1.191480  0.025498  ...  0.088059  2.282780  0.160674   \n",
       "\n",
       "             f93       f94       f95       f96       f97       f98       f99  \n",
       "0      -0.011715  0.052759  0.065400  4.211250  1.978770  0.085974  0.240496  \n",
       "1       0.124863  0.154064  0.606848 -0.267928  2.577860 -0.020877  0.024719  \n",
       "2       0.032396  0.116092 -0.001688 -0.520069  2.141120  0.124464  0.148209  \n",
       "3      -0.008100  0.062013  0.041193  0.511657  1.968600  0.040017  0.044873  \n",
       "4       0.105616  0.125072  0.037509  1.043790  1.074810 -0.012819  0.072798  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "599995  0.017643  0.225133  0.073179  4.436510  1.739330  0.049038  0.065804  \n",
       "599996  0.081926  0.234041  0.041383  3.873990  1.870100  0.162313  0.085662  \n",
       "599997  0.109668  0.027466  0.061931 -0.383329  0.922113  0.084864  0.052635  \n",
       "599998  0.071452 -0.038071  0.038829 -0.122888  3.107790  0.061333  0.004179  \n",
       "599999  0.029301  1.059810  0.007639  3.732990  1.965300  0.049075  0.044436  \n",
       "\n",
       "[600000 rows x 100 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ce7a1ed-9af2-4f5c-9283-b3539329b907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382553</td>\n",
       "      <td>0.705772</td>\n",
       "      <td>-0.315075</td>\n",
       "      <td>0.347277</td>\n",
       "      <td>-0.229657</td>\n",
       "      <td>-0.875660</td>\n",
       "      <td>0.660314</td>\n",
       "      <td>-0.197064</td>\n",
       "      <td>-0.286162</td>\n",
       "      <td>-0.289270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.537157</td>\n",
       "      <td>-0.872508</td>\n",
       "      <td>-0.258806</td>\n",
       "      <td>-0.595537</td>\n",
       "      <td>-0.199502</td>\n",
       "      <td>-0.196145</td>\n",
       "      <td>1.067358</td>\n",
       "      <td>-0.400887</td>\n",
       "      <td>-0.167145</td>\n",
       "      <td>0.443374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347377</td>\n",
       "      <td>-0.530387</td>\n",
       "      <td>-0.417061</td>\n",
       "      <td>0.472862</td>\n",
       "      <td>-0.187909</td>\n",
       "      <td>1.623543</td>\n",
       "      <td>-0.910506</td>\n",
       "      <td>-1.963980</td>\n",
       "      <td>1.309644</td>\n",
       "      <td>-0.229122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573313</td>\n",
       "      <td>0.658473</td>\n",
       "      <td>-0.252018</td>\n",
       "      <td>0.548089</td>\n",
       "      <td>0.019765</td>\n",
       "      <td>2.392938</td>\n",
       "      <td>-1.806811</td>\n",
       "      <td>-0.008064</td>\n",
       "      <td>-0.412110</td>\n",
       "      <td>-0.371198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.517136</td>\n",
       "      <td>-0.643571</td>\n",
       "      <td>-0.132486</td>\n",
       "      <td>-0.293650</td>\n",
       "      <td>-0.361533</td>\n",
       "      <td>0.364863</td>\n",
       "      <td>1.507175</td>\n",
       "      <td>0.824771</td>\n",
       "      <td>-0.480372</td>\n",
       "      <td>-0.183401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408845</td>\n",
       "      <td>1.580886</td>\n",
       "      <td>-0.127714</td>\n",
       "      <td>-0.226174</td>\n",
       "      <td>-0.062423</td>\n",
       "      <td>-0.516946</td>\n",
       "      <td>-1.968603</td>\n",
       "      <td>-0.294434</td>\n",
       "      <td>-0.078904</td>\n",
       "      <td>0.094984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.613619</td>\n",
       "      <td>-1.448884</td>\n",
       "      <td>0.857867</td>\n",
       "      <td>-0.490286</td>\n",
       "      <td>-0.409357</td>\n",
       "      <td>-0.656445</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>1.255833</td>\n",
       "      <td>1.281843</td>\n",
       "      <td>-0.025780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.768719</td>\n",
       "      <td>0.667692</td>\n",
       "      <td>-0.314304</td>\n",
       "      <td>-0.565262</td>\n",
       "      <td>-0.179472</td>\n",
       "      <td>-0.311897</td>\n",
       "      <td>-1.306572</td>\n",
       "      <td>-0.407556</td>\n",
       "      <td>-0.272505</td>\n",
       "      <td>-0.295118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.592913</td>\n",
       "      <td>0.783666</td>\n",
       "      <td>-0.272802</td>\n",
       "      <td>-0.323841</td>\n",
       "      <td>-0.382205</td>\n",
       "      <td>-0.293270</td>\n",
       "      <td>0.930480</td>\n",
       "      <td>-1.684456</td>\n",
       "      <td>0.543499</td>\n",
       "      <td>-0.237512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510155</td>\n",
       "      <td>-0.346112</td>\n",
       "      <td>-0.361423</td>\n",
       "      <td>0.386926</td>\n",
       "      <td>-0.042986</td>\n",
       "      <td>-0.329511</td>\n",
       "      <td>-0.965117</td>\n",
       "      <td>-0.993613</td>\n",
       "      <td>-0.393636</td>\n",
       "      <td>-0.189697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>-0.504355</td>\n",
       "      <td>-0.551500</td>\n",
       "      <td>1.937940</td>\n",
       "      <td>-1.010581</td>\n",
       "      <td>1.585028</td>\n",
       "      <td>-0.552446</td>\n",
       "      <td>0.731375</td>\n",
       "      <td>-0.944482</td>\n",
       "      <td>-0.673772</td>\n",
       "      <td>-0.371060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219391</td>\n",
       "      <td>-0.578403</td>\n",
       "      <td>-0.136659</td>\n",
       "      <td>-0.349704</td>\n",
       "      <td>0.173589</td>\n",
       "      <td>-0.158944</td>\n",
       "      <td>1.211901</td>\n",
       "      <td>-0.557888</td>\n",
       "      <td>-0.251825</td>\n",
       "      <td>-0.216101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>-0.324356</td>\n",
       "      <td>1.498871</td>\n",
       "      <td>-0.736379</td>\n",
       "      <td>-1.076453</td>\n",
       "      <td>-0.335670</td>\n",
       "      <td>0.477988</td>\n",
       "      <td>-0.145691</td>\n",
       "      <td>2.175439</td>\n",
       "      <td>-1.084892</td>\n",
       "      <td>-0.341576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337680</td>\n",
       "      <td>-0.712645</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>0.188558</td>\n",
       "      <td>0.192870</td>\n",
       "      <td>-0.310986</td>\n",
       "      <td>0.850947</td>\n",
       "      <td>-0.472142</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>-0.141134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>1.932651</td>\n",
       "      <td>-1.284110</td>\n",
       "      <td>-0.435725</td>\n",
       "      <td>-0.268614</td>\n",
       "      <td>-0.282193</td>\n",
       "      <td>0.778789</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.377122</td>\n",
       "      <td>-0.967558</td>\n",
       "      <td>-0.258913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407256</td>\n",
       "      <td>-0.170709</td>\n",
       "      <td>-0.223473</td>\n",
       "      <td>0.420855</td>\n",
       "      <td>-0.254249</td>\n",
       "      <td>-0.212734</td>\n",
       "      <td>-1.880861</td>\n",
       "      <td>-1.093736</td>\n",
       "      <td>-0.169690</td>\n",
       "      <td>-0.265813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>0.393168</td>\n",
       "      <td>0.855770</td>\n",
       "      <td>0.854070</td>\n",
       "      <td>-1.529262</td>\n",
       "      <td>0.819921</td>\n",
       "      <td>0.131849</td>\n",
       "      <td>-0.113459</td>\n",
       "      <td>-0.652033</td>\n",
       "      <td>-0.369953</td>\n",
       "      <td>0.776531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>-1.347007</td>\n",
       "      <td>-0.153752</td>\n",
       "      <td>0.100857</td>\n",
       "      <td>-0.396098</td>\n",
       "      <td>-0.323202</td>\n",
       "      <td>-1.713743</td>\n",
       "      <td>0.339410</td>\n",
       "      <td>-0.223636</td>\n",
       "      <td>-0.448741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>-0.243393</td>\n",
       "      <td>0.617626</td>\n",
       "      <td>-0.264700</td>\n",
       "      <td>0.420464</td>\n",
       "      <td>-0.179803</td>\n",
       "      <td>-0.423988</td>\n",
       "      <td>-1.689122</td>\n",
       "      <td>-0.321625</td>\n",
       "      <td>-0.878542</td>\n",
       "      <td>-0.258057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149194</td>\n",
       "      <td>-0.104823</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>-0.252094</td>\n",
       "      <td>1.980194</td>\n",
       "      <td>-0.472343</td>\n",
       "      <td>0.760471</td>\n",
       "      <td>-0.409719</td>\n",
       "      <td>-0.251740</td>\n",
       "      <td>-0.296767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0      -0.382553  0.705772 -0.315075  0.347277 -0.229657 -0.875660  0.660314   \n",
       "1      -0.347377 -0.530387 -0.417061  0.472862 -0.187909  1.623543 -0.910506   \n",
       "2      -0.517136 -0.643571 -0.132486 -0.293650 -0.361533  0.364863  1.507175   \n",
       "3      -0.613619 -1.448884  0.857867 -0.490286 -0.409357 -0.656445 -0.001055   \n",
       "4      -0.592913  0.783666 -0.272802 -0.323841 -0.382205 -0.293270  0.930480   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "599995 -0.504355 -0.551500  1.937940 -1.010581  1.585028 -0.552446  0.731375   \n",
       "599996 -0.324356  1.498871 -0.736379 -1.076453 -0.335670  0.477988 -0.145691   \n",
       "599997  1.932651 -1.284110 -0.435725 -0.268614 -0.282193  0.778789 -0.028331   \n",
       "599998  0.393168  0.855770  0.854070 -1.529262  0.819921  0.131849 -0.113459   \n",
       "599999 -0.243393  0.617626 -0.264700  0.420464 -0.179803 -0.423988 -1.689122   \n",
       "\n",
       "              f7        f8        f9  ...       f90       f91       f92  \\\n",
       "0      -0.197064 -0.286162 -0.289270  ... -0.537157 -0.872508 -0.258806   \n",
       "1      -1.963980  1.309644 -0.229122  ...  0.573313  0.658473 -0.252018   \n",
       "2       0.824771 -0.480372 -0.183401  ...  0.408845  1.580886 -0.127714   \n",
       "3       1.255833  1.281843 -0.025780  ... -0.768719  0.667692 -0.314304   \n",
       "4      -1.684456  0.543499 -0.237512  ... -0.510155 -0.346112 -0.361423   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "599995 -0.944482 -0.673772 -0.371060  ... -0.219391 -0.578403 -0.136659   \n",
       "599996  2.175439 -1.084892 -0.341576  ...  0.337680 -0.712645 -0.114522   \n",
       "599997  0.377122 -0.967558 -0.258913  ...  0.407256 -0.170709 -0.223473   \n",
       "599998 -0.652033 -0.369953  0.776531  ...  0.010571 -1.347007 -0.153752   \n",
       "599999 -0.321625 -0.878542 -0.258057  ...  0.149194 -0.104823  0.009872   \n",
       "\n",
       "             f93       f94       f95       f96       f97       f98       f99  \n",
       "0      -0.595537 -0.199502 -0.196145  1.067358 -0.400887 -0.167145  0.443374  \n",
       "1       0.548089  0.019765  2.392938 -1.806811 -0.008064 -0.412110 -0.371198  \n",
       "2      -0.226174 -0.062423 -0.516946 -1.968603 -0.294434 -0.078904  0.094984  \n",
       "3      -0.565262 -0.179472 -0.311897 -1.306572 -0.407556 -0.272505 -0.295118  \n",
       "4       0.386926 -0.042986 -0.329511 -0.965117 -0.993613 -0.393636 -0.189697  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "599995 -0.349704  0.173589 -0.158944  1.211901 -0.557888 -0.251825 -0.216101  \n",
       "599996  0.188558  0.192870 -0.310986  0.850947 -0.472142  0.007868 -0.141134  \n",
       "599997  0.420855 -0.254249 -0.212734 -1.880861 -1.093736 -0.169690 -0.265813  \n",
       "599998  0.100857 -0.396098 -0.323202 -1.713743  0.339410 -0.223636 -0.448741  \n",
       "599999 -0.252094  1.980194 -0.472343  0.760471 -0.409719 -0.251740 -0.296767  \n",
       "\n",
       "[600000 rows x 100 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X[cols] = scaler.fit_transform(X[cols])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30c7afac-6fbe-4200-bd98-c49e786757ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa1e1ce3-bd3c-48c0-bc0a-496ca0e1c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(model, params):\n",
    "    grid_search = GridSearchCV(model, param_grid=params, cv=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print('best parameters : ', grid_search.best_params_)\n",
    "    print('best score : ', grid_search.best_score_)\n",
    "    y_pred = grid_search.predict(X_valid)\n",
    "    print('validation score ',accuracy_score(y_valid,y_pred))\n",
    "    print('rmse score : ',rmse(y_valid,y_pred))\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a8ad842-4de1-46c0-9f59-eadc92b352c4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters :  {'colsample_bytree': 0.35, 'max_depth': 15, 'n_estimators': 4100, 'num_leaves': 21, 'subsample': 0.4}\n",
      "best score :  0.7038875\n",
      "validation score  0.7091833333333334\n",
      "rmse score :  0.5392742035983797\n"
     ]
    }
   ],
   "source": [
    "lgbm_params = { 'n_estimators' : [4100], 'colsample_bytree' : [0.35, 0.55,0.7],\n",
    "              'max_depth' : [4,6,15], 'num_leaves' : [21, 31,41],\n",
    "               'subsample' : [0.4, 0.6]\n",
    "              }\n",
    "lgbm_clf = LGBMClassifier( learning_rate=0.07, boosting_type='gbdt',\n",
    "                           reg_lambda=5, n_jobs=10,\n",
    "                          device=\"cuda\"\n",
    "                          \n",
    "                         )\n",
    "best_lgbm = get_best_params(lgbm_clf, lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7a091ba-e987-4b43-8fcb-3643aee12184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.35,\n",
       " 'max_depth': 15,\n",
       " 'n_estimators': 4100,\n",
       " 'num_leaves': 21,\n",
       " 'subsample': 0.4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c596584-f379-4ad3-8d7b-468d7359303d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "#!stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a16783b-854c-4d8e-a11a-328680adefc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a29fedb9-fdec-4c7a-8c0e-0e9871cd3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    # rf : Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /media/2/hwbae0326/package/LightGBM/src/boosting/rf.hpp\n",
    "    lgbm_clf = LGBMClassifier( boosting_type='gbdt', class_weight=None,\n",
    "               colsample_bytree=0.35, #feature_fraction=0.15, # same thing\n",
    "               importance_type='split', learning_rate=0.1, max_depth=15,\n",
    "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "               n_estimators=4100,  num_leaves=21, objective=None,\n",
    "               random_state=None, reg_alpha=0.0, reg_lambda=5, silent=True,\n",
    "               #bagging_fraction=0.2,\n",
    "               subsample=0.4, subsample_for_bin=200000,  subsample_freq=0,\n",
    "                             n_jobs=10, device=\"cuda\")\n",
    "    return lgbm_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33e73487-542a-4598-b1fd-aaf7f159dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits=3, random_state=33, shuffle=True)\n",
    "preds = np.zeros(test.shape[0])\n",
    "auc = []\n",
    "acc = []\n",
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "132c4c39-7ad6-424a-a378-9a9fd6b26b79",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1 , accuracy: 69.686 , auc: 73.591\n",
      "rmse : 0.5506\n",
      "fold: 2 , accuracy: 69.363 , auc: 73.383\n",
      "rmse : 0.5535\n",
      "fold: 3 , accuracy: 69.535 , auc: 73.441\n",
      "rmse : 0.5520\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in kf.split(X_train[cols],y_train):\n",
    "    xtrain, xval = X_train[cols].iloc[train_idx], X_train[cols].iloc[test_idx]\n",
    "    ytrain, yval = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    model = load_model()\n",
    "    model.fit(xtrain, ytrain, eval_set =[(xval,yval)], verbose=False)\n",
    "    local_preds =  model.predict(test_df[cols]) # /kf.nsplits\n",
    "    # print(local_preds, local_preds.shape)\n",
    "    preds += local_preds\n",
    "    auc.append(roc_auc_score(yval, model.predict_proba(xval)[:, 1]))\n",
    "    acc.append(accuracy_score(yval, model.predict(xval)))\n",
    "\n",
    "    print(f\"fold: {n+1} , accuracy: {round(acc[n]*100,3)} , auc: {round(auc[n]*100,3)}\")\n",
    "    val_pred = model.predict(xval)\n",
    "    print('rmse : %.4f'%(rmse(val_pred,yval)))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ffcd066b-dd65-4173-b01e-0c50b990dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgbm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b8f15aa-e8d6-485f-8006-23ebcd94a56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 4 , accuracy: 70.547 , auc: 73.803\n",
      "rmse : 0.5427\n",
      "fold: 5 , accuracy: 70.158 , auc: 73.451\n",
      "rmse : 0.5463\n",
      "fold: 6 , accuracy: 69.57 , auc: 73.252\n",
      "rmse : 0.5516\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=3, random_state=33, shuffle=True)\n",
    "for train_idx, test_idx in kf.split(X_train[cols],y_train):\n",
    "    xtrain, xval = X_train[cols].iloc[train_idx], X_train[cols].iloc[test_idx]\n",
    "    ytrain, yval = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    model = LogisticRegression( n_jobs=10)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    local_preds =  model.predict(test_df[cols]) # /kf.nsplits\n",
    "    # print(local_preds, local_preds.shape)\n",
    "    preds += local_preds\n",
    "    auc.append(roc_auc_score(yval, model.predict_proba(xval)[:, 1]))\n",
    "    acc.append(accuracy_score(yval, model.predict(xval)))\n",
    "\n",
    "    print(f\"fold: {n+1} , accuracy: {round(acc[n]*100,3)} , auc: {round(auc[n]*100,3)}\")\n",
    "    val_pred = model.predict(xval)\n",
    "    print('rmse : %.4f'%(rmse(val_pred,yval)))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee607441-ca79-4c35-97b3-31d88f24ae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 7 , accuracy: 67.709 , auc: 71.952\n",
      "rmse : 0.5682\n",
      "fold: 8 , accuracy: 67.566 , auc: 71.751\n",
      "rmse : 0.5695\n",
      "fold: 9 , accuracy: 67.604 , auc: 71.745\n",
      "rmse : 0.5692\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=3, random_state=33, shuffle=True)\n",
    "for train_idx, test_idx in kf.split(X_train[cols],y_train):\n",
    "    xtrain, xval = X_train[cols].iloc[train_idx], X_train[cols].iloc[test_idx]\n",
    "    ytrain, yval = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    model = GradientBoostingClassifier() # XGBClassifier\n",
    "    model.fit(xtrain, ytrain)\n",
    "    local_preds =  model.predict(test_df[cols]) # /kf.nsplits\n",
    "    # print(local_preds, local_preds.shape)\n",
    "    preds += local_preds\n",
    "    auc.append(roc_auc_score(yval, model.predict_proba(xval)[:, 1]))\n",
    "    acc.append(accuracy_score(yval, model.predict(xval)))\n",
    "\n",
    "    print(f\"fold: {n+1} , accuracy: {round(acc[n]*100,3)} , auc: {round(auc[n]*100,3)}\")\n",
    "    val_pred = model.predict(xval)\n",
    "    print('rmse : %.4f'%(rmse(val_pred,yval)))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a984fcc7-43df-4d58-ba0b-e629318e9e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/2/hwbae0326/anaconda3/envs/kaggle/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:35:35] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fold: 10 , accuracy: 68.821 , auc: 72.875\n",
      "rmse : 0.5584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/2/hwbae0326/anaconda3/envs/kaggle/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:20] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fold: 11 , accuracy: 68.742 , auc: 72.643\n",
      "rmse : 0.5591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/2/hwbae0326/anaconda3/envs/kaggle/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:04] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fold: 12 , accuracy: 68.859 , auc: 72.747\n",
      "rmse : 0.5580\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=3, random_state=33, shuffle=True)\n",
    "for train_idx, test_idx in kf.split(X_train[cols],y_train):\n",
    "    xtrain, xval = X_train[cols].iloc[train_idx], X_train[cols].iloc[test_idx]\n",
    "    ytrain, yval = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "    model.fit(xtrain, ytrain)\n",
    "    local_preds =  model.predict(test_df[cols]) # /kf.nsplits\n",
    "    # print(local_preds, local_preds.shape)\n",
    "    preds += local_preds\n",
    "    auc.append(roc_auc_score(yval, model.predict_proba(xval)[:, 1]))\n",
    "    acc.append(accuracy_score(yval, model.predict(xval)))\n",
    "\n",
    "    print(f\"fold: {n+1} , accuracy: {round(acc[n]*100,3)} , auc: {round(auc[n]*100,3)}\")\n",
    "    val_pred = model.predict(xval)\n",
    "    print('rmse : %.4f'%(rmse(val_pred,yval)))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed3c998c-72cd-48df-aa18-e1bd12cc71a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.91666667, 1.        , ..., 0.58333333, 1.        ,\n",
       "       0.91666667])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = preds / n\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b372992-f18b-4006-8c8c-d83515de91e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9df0d900-e1ce-43ff-843d-d770e1e01580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600001</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600002</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600003</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600004</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539995</th>\n",
       "      <td>1139995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539996</th>\n",
       "      <td>1139996</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539997</th>\n",
       "      <td>1139997</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539998</th>\n",
       "      <td>1139998</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539999</th>\n",
       "      <td>1139999</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id    target\n",
       "0        600000  1.000000\n",
       "1        600001  0.916667\n",
       "2        600002  1.000000\n",
       "3        600003  0.750000\n",
       "4        600004  0.166667\n",
       "...         ...       ...\n",
       "539995  1139995  1.000000\n",
       "539996  1139996  1.000000\n",
       "539997  1139997  0.583333\n",
       "539998  1139998  1.000000\n",
       "539999  1139999  0.916667\n",
       "\n",
       "[540000 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(DATASET_PATH+'/sample_submission.csv')\n",
    "sub['target'] = preds\n",
    "sub.to_csv('submission6.csv',index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6deb763-d0e3-4330-a50d-9f607ca4df92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 11.5M/11.5M [00:04<00:00, 2.89MB/s]\n",
      "400 - Bad Request\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23d577-ce99-491a-af92-0146316af66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c tabular-playground-series-nov-2021 -f submission5.csv -m \"LightGBM_7 + LogisticRegression_3 + GradientBoostingClassifier_7 KFold 10\"\n",
    "!kaggle competitions submit -c tabular-playground-series-nov-2021 -f submission6.csv -m \"LightGBM_3 + LogisticRegression_3 + GradientBoostingClassifier_3 + XGBClassifier_3 KFold 10\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
